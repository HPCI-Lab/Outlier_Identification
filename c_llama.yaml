run: 
  epochs: 30
  device: "cpu"
  optimizer: "adam"  
  learning_rate: 1.e-6
  criterion: "CrossEntropyLoss" 
model: 
  type: "llama"
  model_path: "meta-llama/Llama-3.1-8B"
  inner_size: 1280
dataset: 
  type: "med"
  samples_per_class: 1000
  classes: 5
  batch_size: 32
  shuffle: True
  outlier_number: 3
  outlier_range: 1
  outlier_distance: 0
  context_len: 200
detection: 
  keep_epochs: []
  use_pca: True
  window_size: 2
  techniques: ["wlf", "maha", "lof"]
  metrics: ["Loss", "Step_time"]
identification: 
  window_size: 2
  keep_epochs: []
  techniques: ["value_counting"]
  metrics: ["Loss", "Step_time"]